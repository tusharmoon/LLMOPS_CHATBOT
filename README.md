ğŸ“„ Resume Analyzer â€“ RAG-Based AI Chatbot

Resume Analyzer is an intelligent, Retrieval-Augmented Generation (RAG) based chatbot designed to analyze and interact with multiple resumes using natural language. The application enables recruiters, hiring managers, and analysts to ask contextual questions about candidate profiles and receive accurate, resume-grounded responses in a conversational format.

The system processes resumes (PDF/DOCX), converts them into semantic embeddings, and stores them in a vector database for efficient similarity search. When a user asks a question, the chatbot retrieves the most relevant resume chunks and leverages a Large Language Model (LLM) to generate precise, explainable answers strictly based on the retrieved content.

The application features a chat-style Streamlit frontend, offering a seamless user experience similar to modern AI assistants, while the backend is built using LangChain, Mistral LLM, and vector search techniques.

ğŸš€ Key Features

        ğŸ’¬ Chatbot Interface â€“ Interactive, conversational UI built with Streamlit

        ğŸ“‚ Multi-Resume Analysis â€“ Supports querying across multiple candidate resumes

        ğŸ” Context-Aware Answers â€“ Uses RAG to ensure responses are grounded in resume data

        ğŸ§  Semantic Search â€“ Embedding-based retrieval for accurate context matching

        ğŸ“„ Multiple File Formats â€“ Supports PDF and DOCX resumes

        âš¡ Efficient & Scalable â€“ Embeddings and retriever cached for faster responses

        ğŸ” Configurable LLM Backend â€“ Easily switch or extend LLM providers

ğŸ§© Tech Stack

        Frontend: Streamlit

        Backend: Python, LangChain

        LLM: Mistral

        Vector Store: Embedding-based vector database

        Document Processing: PDF & DOCX loaders

        Environment Management: Python .env configuration

ğŸ¯ Use Cases

        Resume screening and shortlisting

        Skill and experience comparison

        Candidate profiling

        Interview preparation support

        HR analytics and talent insights

ğŸ—ï¸ Architecture Overview

        Resumes are loaded and preprocessed

        Documents are chunked and embedded

        Embeddings are stored in a vector database

        User queries retrieve relevant resume context

        LLM generates grounded, contextual responses

        Answers are displayed via a chat-based UI

Folder Structure:

        â”œâ”€â”€ app.py              # Streamlit UI
        â”œâ”€â”€ src/                # Backend logic
        â”‚   â”œâ”€â”€ load_doc.py
        â”‚   â”œâ”€â”€ vector_store.py
        â”‚   â”œâ”€â”€ prompts.py
        â”‚   â””â”€â”€ load_llm.py
        â”œâ”€â”€ data/resumes/       # Resume files
        â”œâ”€â”€ requirements.txt
        â””â”€â”€ README.md

